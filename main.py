import random
import time
import os
from pprint import pprint
import json
import requests
from pyppeteer import launch
import asyncio
import smtplib
from email.mime.image import MIMEImage
from email.header import Header
import schedule

with open('UA.in') as f:
    ua_list = [x.split('\n')[0] for x in f.readlines()]

get_random_ua = lambda: random.choice(ua_list)
SECRET_PASS = 'your secret pass'
reply_message = 'ğŸ“¢ åœ¨æœ€ç¾çš„å¹´åï¼Œåšæœ€å–œæ¬¢çš„äº‹æƒ…çš„è¯´ï¼Œåˆ«è¾œè´Ÿäº†ç¾å¥½æ—¶å…‰ã€‚å€Ÿæ—¶å…‰ä¹‹æ‰‹ï¼Œæš–ä¸€å¤„èŠ±å¼€ï¼Œå€Ÿä¸€æ–¹æ™´ç©ºï¼Œæ‹¥æŠ±æ¢¦æƒ³çš„è¯´ã€‚æ—©å®‰çš„è¯´ï¼'

no_cat = True


def run_for_no_cat(fun):
    def empty_f():
        pass

    return fun if no_cat else empty_f


@run_for_no_cat
def crawler():
    header = {
        'User-Agent': get_random_ua()
    }
    response = requests.get(
        'https://m.weibo.cn/api/container/getIndex?type=uid&value=5648729445&containerid=1076035648729445',
        headers=header)
    try:
        data = json.loads(response.text)
        pprint(data)
    except TypeError as e:
        print(e.args)
    finally:
        if data.get('ok'):
            cards = data.get('data', {}).get('cards', {})
            try:
                text = cards[1]['mblog']['text']
                if text.startswith('å’•çŒ«') or True:
                    no_cat = False
                    cat_scheme = cards[1]['scheme']
                    # await weibo-qq-login and reply
                    asyncio.get_event_loop().run_until_complete(reply())
            except IndexError as ie:
                print(ie.args)


async def reply(cat_scheme: str = ''):
    # create_url = 'https://m.weibo.cn/api/comments/create'
    browser = await launch(
        headless=False,
        # ignoreDefaultArgs="--enable-automation"
    )
    page = await browser.newPage()
    await page.setUserAgent(get_random_ua())
    await page.setJavaScriptEnabled(enabled=True)
    await page.goto(url='https://passport.weibo.cn/signin/other?r=https%3A%2F%2Fm.weibo.cn')
    url = page.url
    print(url)
    await page.click('i[class="icon forQQ"]')
    # ç­‰å¾…äºŒç»´ç 
    await asyncio.sleep(5)
    await page.screenshot({'path': './weibo-qq-login.png', 'quality': 100, 'fullPage': True})
    # å‘é€é‚®ä»¶
    mail_smtp()
    # os.remove('./weibo-qq-login.png')
    await asyncio.sleep(10)
    cookies=await page.cookies()
    print(cookies)
    return page.cookies
    await page.goto(cat_scheme)
    while True:
        try:
            await page.type(
                selector='#app > div.lite-page-wrap > div > div.lite-page-editor > div > div > div > div.textarea-box > textarea:nth-child(1)',
                text=reply_message
            )
            await page.click(
                '#app > div.lite-page-wrap > div > div.lite-page-editor > div > div > div > div.flex-row.composer-mini-bar > button')
            await asyncio.sleep(5)
        except:
            await asyncio.sleep(1)
        else:
            break



def mail_smtp():
    mail_host = 'smtp.qq.com'
    mail_pass = SECRET_PASS

    mail_user = '616200285@qq.com'
    to_list = ['wohfacm@163.com']
    with open('./weibo-qq-login.png', 'rb') as png:
        message = MIMEImage(png.read())
    message['From'] = mail_user
    message['To'] = ",".join(to_list)

    subject = 'Aå²›ç™»é™†å•¦'  # é‚®ä»¶ä¸»é¢˜
    message['Subject'] = Header(subject, 'utf-8')
    message.add_header('Content-Disposition', 'attachment', filename="weibo-qq-login.png")
    try:
        smtpObj = smtplib.SMTP()
        smtpObj.connect(mail_host, 25)  # 25 ä¸º SMTP ç«¯å£å·
        smtpObj.login(mail_user, mail_pass)
        smtpObj.sendmail(mail_user, to_list, message.as_string())
        print("é‚®ä»¶å‘é€æˆåŠŸ")
    except smtplib.SMTPException as e:
        print(e.args)
        print("Error: æ— æ³•å‘é€é‚®ä»¶")


def test():
    crawler()


def main():
    schedule.every(5).minutes.at(':05').do(crawler)
    schedule.every(5).minutes.at(':06').do(crawler)
    schedule.every(5).minutes.at(':07').do(crawler)
    schedule.every(5).minutes.at(':08').do(crawler)
    schedule.every(5).minutes.at(':09').do(crawler)

    while True:
        schedule.run_pending()
        time.sleep(1)


if __name__ == "__main__":
    test()
